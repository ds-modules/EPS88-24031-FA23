{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    " <!-- BEGIN QUESTION -->\n",
    "# The Last Glacial Maximum, ice sheet flow, directional data, and bootstrapping\n",
    "\n",
    "## Import scientific python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "import cartopy.crs as ccrs\n",
    "import otter\n",
    "from cartopy.io.img_tiles import Stamen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "## Ice-flow indicator compilation, British Columbia and Yukon\n",
    "\n",
    "The data set we will focus on today is a large compilation of indicators of past ice-flow that was published by the British Columbia Geological Survey.\n",
    "\n",
    "> Publication Information:\n",
    "*Ice-flow indicator compilation, British Columbia and Yukon\n",
    "British Columbia Ministry of Energy and Mines, British Columbia Geological Survey Open File 2016-04\n",
    "Geological Survey of Canada Open File 8083\n",
    "H. Arnold, T. Ferbey and A.S. Hickin*\n",
    "\n",
    "> A better understanding of the Cordilleran ice sheet flow history is important for designing, implementing, and interpreting geochemical and mineralogical data from drift prospecting surveys. Building on ice-flow indicator compilations for British Columbia by Ferbey et al. (2013) and Yukon Territory (Lipovsky and Bond, 2014), this map and database illustrate major ice-flow directions for the Canadian sector of Cordilleran ice sheet during the Late Pleistocene.\n",
    "\n",
    "> The data were derived from published and unpublished surficial geology, terrain, and glacial feature maps. Because field data are sparse in the area ~ 300 km south of the British Columbia -Yukon border, new data were generated using digital stereo airphotos, digital derived-stereo orthophoto mosaics, and digital derived-stereo Satellite Pour l'Observation de la Terre (SPOT) imagery. The raw data are integrated into a single database; no attempt was made to reconcile cases where data from different sources conflict. \n",
    "\n",
    "> The report and database is an openfile report of the British Columbia Geological Survey of Canada; http://cmscontent.nrs.gov.bc.ca/geoscience/PublicationCatalogue/OpenFile/BCGS_OF2020-03.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "ice_directions = pd.read_csv('./data/trimmed_ice_directions.csv')\n",
    "ice_directions.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "## How do Earth scientists determine the extent and direction of ice sheet flow?\n",
    "\n",
    "As covered in the reading, there the presence of ice lead to a number of different types of features. **What types of features are used in this data set? Let's get all the unique values in the 'Feature' column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "ice_directions['Feature'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "## Plotting the direction of one measurement\n",
    "\n",
    "### Azimuth\n",
    "\n",
    "Earth science is filled with directional data. The most typical way that directional data are reported is as azimuth:\n",
    "\n",
    "<img src=\"./figures/azimuth.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "Let's look at the azimuth of the first data point in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "ice_directions.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "first_azimuth = ice_directions['Azimuth'][0]\n",
    "print(first_azimuth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "## Getting the x length and y length of the unit vector associated with the azimuth\n",
    "\n",
    "<img src=\"./figures/Circle_cos_sin.gif\" width = 600>\n",
    "\n",
    "If $\\theta=0ยบ$ $sin(\\theta)=1$ and $cos(\\theta)=0$\n",
    "\n",
    "If $\\theta=90ยบ$ $sin(\\theta)=0$ and $cos(\\theta)=1$\n",
    "\n",
    "If $\\theta=225ยบ$ $sin(\\theta)= -0.7071$ and $cos(\\theta)= -0.7071$\n",
    "\n",
    "Unfortunately, the trignometric convention is rotated 90ยบ from the geographic convention, but the result is that:\n",
    "\n",
    "x_length = sin(azimuth)\n",
    "\n",
    "y_length = cos(azimuth)\n",
    "\n",
    "<img src=\"./figures/2D_Direction_Vectors.svg\" width = 600>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "def get_arrow_lengths(azimuth):\n",
    "    azimuth_radians = np.radians(azimuth)\n",
    "    x_length = np.sin(azimuth_radians)\n",
    "    y_length = np.cos(azimuth_radians)\n",
    "    return x_length,y_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "get_arrow_lengths(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "x_length,y_length = get_arrow_lengths(first_azimuth)\n",
    "\n",
    "plt.arrow(0, 0, x_length, y_length,length_includes_head=True,\n",
    "         head_width=0.1, head_length=0.1,color='red')    \n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(-1,1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "<font color=goldenrod>**_Code for you to write_**</font>\n",
    "\n",
    "Use the ```get_arrow_length``` function and add an green arrow pointed north (azimuth of 0) and an orange one pointed southeast (azimuth of 135) onto the plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "## Calculate the x length and y length associated with the unit vector of each azimuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "ice_directions['x_length'],ice_directions['y_length'] = get_arrow_lengths(ice_directions['Azimuth'])\n",
    "ice_directions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "## Plot the data on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "tiler = Stamen('terrain-background')\n",
    "mercator = tiler.crs\n",
    "ax = plt.axes(projection=mercator)\n",
    "ax.set_extent([-150, -110, 45, 70])\n",
    "ax.add_image(tiler, 4)\n",
    "ax.coastlines('10m')\n",
    "\n",
    "plt.quiver(np.array(ice_directions['Long']),np.array(ice_directions['Lat']),\n",
    "           np.array(ice_directions['x_length']),np.array(ice_directions['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "## Subsample the data\n",
    "\n",
    "It is great that there are so many datapoints, but it makes it hard to see what the directions are. Let's take a subsample of the data:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html\n",
    "\n",
    "We can use the pandas function ```.sample``` to do so specifying how many samples. This function randomly samples values from those available in the dataframe. In this case, we will want ```replace=False``` so that we don't sample the same datapoint twice. We will use this function again later when we bootstrap for uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "Let's grab 1000 samples and plot them. We could be even more clever and develop a function that sampled with spatial awareness, but for now, let's sample 1000 data points and then plot them on the same map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "ice_directions_subsample = ice_directions.sample(1000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "tiler = Stamen('terrain-background')\n",
    "mercator = tiler.crs\n",
    "ax = plt.axes(projection=mercator)\n",
    "ax.set_extent([-150, -110, 45, 70])\n",
    "ax.add_image(tiler, 4)\n",
    "ax.coastlines('10m')\n",
    "\n",
    "plt.quiver(np.array(ice_directions_subsample['Long']),np.array(ice_directions_subsample['Lat']),\n",
    "           np.array(ice_directions_subsample['x_length']),np.array(ice_directions_subsample['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "Another way to visualize all these data on a map would be to change their color based on direction.\n",
    "\n",
    "<font color=goldenrod>**_Code for you to write_**</font>\n",
    "\n",
    "Make a data frame called ```ice_directions_west``` for flow directions that have an 'Azimuth' greater than 180 and a data frame called ```ice_directions_east``` for flow directions that have an 'Azimuth' less than 180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "tiler = Stamen('terrain-background')\n",
    "mercator = tiler.crs\n",
    "ax = plt.axes(projection=mercator)\n",
    "ax.set_extent([-150, -110, 45, 70])\n",
    "ax.add_image(tiler, 4)\n",
    "ax.coastlines('10m')\n",
    "\n",
    "plt.quiver(np.array(ice_directions_west['Long']),np.array(ice_directions_west['Lat']),\n",
    "           np.array(ice_directions_west['x_length']),np.array(ice_directions_west['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='red',alpha=0.1)\n",
    "plt.quiver(np.array(ice_directions_east['Long']),np.array(ice_directions_east['Lat']),\n",
    "           np.array(ice_directions_east['x_length']),np.array(ice_directions_east['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='blue',alpha=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "It is easier to see some of the directions, but it would be nice to summarize their orientations. We have summarized data using histograms before so let's go ahead and do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "## Visualizing the directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "plt.hist(ice_directions['Azimuth'])\n",
    "plt.xlabel('azimuth flow direction')\n",
    "plt.ylabel('number of flow indicators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "**Why are histograms not great for visualizing such data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "### Rose diagrams\n",
    "\n",
    "*Text modified from Lisa Tauxe's materials for her Python for Earth Science Students course: https://github.com/ltauxe/Python-for-Earth-Science-Students*\n",
    "\n",
    "As Earth scientists, we like to make plots that convey the most information with the least amount of effort for the viewer.  2D directional data are much better represented as 'rose diagrams', which are really just histograms plotted around a circle. They are also known as _polar_ projections as they could be used to make a map of the Earth looking down at one of the poles.  \n",
    "\n",
    "We will follow these steps: \n",
    "\n",
    "- For rose diagrams, we will create a  plot instance (called ```fig```) with the ```plt.subplot()``` function.  We make it a _polar_ plot by setting the ```polar``` keyword to ```True```. \n",
    "- The _polar_ type of subplot has funny coordinates set as default, funny to an Earth scientist at least.  The orientations go around counterclockwise instead of clockwise (like map directions). To make it seem more normal for Earth science data,  we have to switch around the directions to geographic coordinates.  We do this with the **fig.set_theta_direction(-1)** function where the '-1' tells **matplotlib** that we want the numbers to go around clockwise, instead of the default (which for some unknown reason goes counter clockwise).  \n",
    "- We also have to put '0' at the top of the diagram (because it is 'North' in Earth science).  We do that with the ```fig.set_theta_zero_location('N')``` call, which tells ```matplotlib``` to put 0 on top (instead of on the right side which is the default).  \n",
    "-  We have to define some bins, sort of like histograms but around azimuthal circle, and count up how many directions are in each bin.  We will use a bin size of 10$^{\\circ}$.  Fortunately, ```plt.hist()``` will count up the number of directional data in each bin for us! Usually we just use ```plt.hist()``` to make the plot, but we can also have it return the bins and the number in each bin.\n",
    "- We will use the  plot function **plt.bar()** which normally makes bar charts, but will make rose diagrams if the plot is _polar_.\n",
    "- Finally, we will plot the data on the figure instance. \n",
    "\n",
    "Let's modify the histogram and use `plt.hist()` to count up the number in each bin for each set of striations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "width = 10 # width of the azimuthal bins\n",
    "binarray = np.arange(0,360+width,width) # make an array to use for bins in plt.hist\n",
    "azimuth_counts, azimuth_bins, patches = plt.hist(ice_directions['Azimuth'],bins=binarray) # get back the counts\n",
    "plt.xlabel('azimuth flow direction')\n",
    "plt.ylabel('number of flow indicators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "A few more things.  **plt.bar( )** needs an array of widths that is same same length as our count arrays but with the width (in radians) and also the bin arrays have to be in radians too!  So we need to delete the last bin from binarray and make arrays in radians.\n",
    "\n",
    "So, to finish things off:  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "bins = binarray[0:-1] # delete the last bin\n",
    "thetas = np.radians(bins) # convert the binarray to radians.  \n",
    "widths = np.radians(np.ones(len(thetas))*width) # make the widths array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "Now we are ready to make the plot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "# make the figure instance\n",
    "fig = plt.subplot(111, polar=True) # Specify polar axes\n",
    "# set the coordinates the way we want them\n",
    "fig.set_theta_direction(-1) # Reverse direction of degrees (CW)\n",
    "fig.set_theta_zero_location(\"N\") # Specify 0-degrees as North\n",
    "# use the polar \"bar\" plot.   \n",
    "fig.bar(thetas, azimuth_counts, width=widths, bottom=0, color='darkblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "In and of itself, this result is pretty good. The Cordilleran ice sheet was dominantly flowing to the NE towards the Laurentide ice sheet.\n",
    "\n",
    "<img src=\"./figures/Cordilleran-and-Laurentide-Ice-Sheets.png\" width = 600>\n",
    "\n",
    "But the Cordilleran ice sheet ice sheet is more complicated than that and has zones with different dynamics. Let's zoom-in on Vancouver Island -- west of Vancouver where the lovely coastal city of Victoria is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "tiler = Stamen('terrain-background')\n",
    "mercator = tiler.crs\n",
    "ax = plt.axes(projection=mercator)\n",
    "ax.set_extent([-130, -122, 48, 51.5])\n",
    "ax.add_image(tiler, 4)\n",
    "ax.coastlines('10m')\n",
    "\n",
    "plt.quiver(np.array(ice_directions['Long']),np.array(ice_directions['Lat']),\n",
    "           np.array(ice_directions['x_length']),np.array(ice_directions['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='purple')\n",
    "\n",
    "ax.add_patch(mpatches.Rectangle(xy=[-128.5, 50], width=1.5, height=1,\n",
    "                                    edgecolor='orange',facecolor='none',\n",
    "                                    linewidth=3,\n",
    "                                    transform=ccrs.Geodetic()))\n",
    "\n",
    "ax.add_patch(mpatches.Rectangle(xy=[-126, 49.1], width=1.4, height=1,\n",
    "                                    edgecolor='red',facecolor='none',\n",
    "                                    linewidth=3,\n",
    "                                    transform=ccrs.Geodetic()))\n",
    "\n",
    "ax.add_patch(mpatches.Rectangle(xy=[-124.7, 48.1], width=1.5, height=1,\n",
    "                                    edgecolor='brown',facecolor='none',\n",
    "                                    linewidth=3,\n",
    "                                    transform=ccrs.Geodetic()))\n",
    "                      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "In the map above, I have grouped the data into three zones (north, central and south). Let's filter the dataframe to make separate Vancouver Island north, central and south dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "ice_directions_VI_n = ice_directions[(ice_directions['Long'] < -127.0) & \n",
    "                                     (ice_directions['Long'] > -128.5) &\n",
    "                                     (ice_directions['Lat'] < 51.0) &\n",
    "                                     (ice_directions['Lat'] > 50.0)]\n",
    "\n",
    "ice_directions_VI_c = ice_directions[(ice_directions['Long'] < -124.6) & \n",
    "                                     (ice_directions['Long'] > -126.0) &\n",
    "                                     (ice_directions['Lat'] < 50.1) &\n",
    "                                     (ice_directions['Lat'] > 49.1)]\n",
    "\n",
    "ice_directions_VI_s = ice_directions[(ice_directions['Long'] < -123.2) & \n",
    "                                     (ice_directions['Long'] > -124.7) &\n",
    "                                     (ice_directions['Lat'] < 49.1) &\n",
    "                                     (ice_directions['Lat'] > 48.1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "Let's plot them different colors so that we make sure the filtering worked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "tiler = Stamen('terrain-background')\n",
    "mercator = tiler.crs\n",
    "ax = plt.axes(projection=mercator)\n",
    "ax.set_extent([-130, -122, 48, 51.5])\n",
    "ax.add_image(tiler, 4)\n",
    "ax.coastlines('10m')\n",
    "\n",
    "plt.quiver(np.array(ice_directions_VI_n['Long']),np.array(ice_directions_VI_n['Lat']),\n",
    "           np.array(ice_directions_VI_n['x_length']),np.array(ice_directions_VI_n['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='orange')\n",
    "\n",
    "plt.quiver(np.array(ice_directions_VI_c['Long']),np.array(ice_directions_VI_c['Lat']),\n",
    "           np.array(ice_directions_VI_c['x_length']),np.array(ice_directions_VI_c['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='red')\n",
    "\n",
    "plt.quiver(np.array(ice_directions_VI_s['Long']),np.array(ice_directions_VI_s['Lat']),\n",
    "           np.array(ice_directions_VI_s['x_length']),np.array(ice_directions_VI_s['y_length']),\n",
    "           scale=30,transform=ccrs.PlateCarree(),color='brown')\n",
    "                      \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "def make_rose_diagram(azimuths,color='black',bin_width=10,title='',mean_direction=None):\n",
    "    binarray = np.arange(0,360+bin_width,bin_width) # make an array to use for bins in plt.hist\n",
    "    azimuth_counts, azimuth_bins, patches = plt.hist(azimuths,bins=binarray) # get back the counts\n",
    "    plt.clf()             # clear the current figure - we do this because we will make multiple plots\n",
    "    bins = binarray[0:-1] # delete the last bin\n",
    "    thetas = np.radians(bins) # convert the binarray to radians.  \n",
    "    widths = np.radians(np.ones(len(thetas))*bin_width) # make the widths array\n",
    "\n",
    "    fig = plt.subplot(111, polar=True) # Specify polar axes\n",
    "    fig.set_theta_direction(-1) # Reverse direction of degrees (CW)\n",
    "    fig.set_theta_zero_location(\"N\") # Specify 0-degrees as North\n",
    "    plt.bar(thetas, azimuth_counts, width=widths, bottom=0, color=color)\n",
    "    if mean_direction != None:\n",
    "        plt.bar(np.radians(mean_direction), np.max(azimuth_counts), width=0.01,bottom=0, color='black')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "make_rose_diagram(ice_directions_VI_n['Azimuth'],color='orange',title='northern Victoria ice flow')\n",
    "make_rose_diagram(ice_directions_VI_c['Azimuth'],color='red',title='central Victoria ice flow')\n",
    "make_rose_diagram(ice_directions_VI_s['Azimuth'],color='brown',title='southern Victoria ice flow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "### Compute the mean to enable easier comparison of the flow directionr results.\n",
    "\n",
    "To calculate a mean direction of directional data, we can't just calculate the arithmetic mean. Why? Try finding the mean of\n",
    "\n",
    "azimuth_1 = 6\n",
    "\n",
    "azimuth_2 = 351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "#Calculate mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "This answer is clearly wrong as both of these azimuths are pointed north. What can we do to fix that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "x_length_1,y_length_1 = get_arrow_lengths(azimuth_1)\n",
    "x_length_2,y_length_2 = get_arrow_lengths(azimuth_2)\n",
    "\n",
    "plt.arrow(0, 0, x_length_1, y_length_1,length_includes_head=True,\n",
    "         head_width=0.1, head_length=0.1,color='darkred')   \n",
    "plt.arrow(x_length_1, y_length_1,x_length_2,y_length_2,length_includes_head=True,\n",
    "         head_width=0.1, head_length=0.1,color='darkblue')   \n",
    "plt.ylim(-2,2)\n",
    "plt.xlim(-2,2)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "The resultant vector gives the mean angle\n",
    "\n",
    "<img src=\"./figures/resultant_vector.png\" width = 300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "#Compute the mean azimuth for the two azimuth case\n",
    "\n",
    "#Angles method\n",
    "\n",
    "#Vector method\n",
    "#np.arctan2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "#### Lets put the arctangent to use and define a function to calculate the mean angular direction (replace the `xxx`s below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "#Use the np.arctan2() function to create a defined function\n",
    "x=0\n",
    "y=1\n",
    "np.degrees(np.arctan2(x,y))\n",
    "print(f'x={x:.1f} y={y:.1f} angle={np.degrees(np.arctan2(x,y)):.1f}')\n",
    "\n",
    "def mean_angular_direction(xtotal,ytotal):\n",
    "    xxx\n",
    "    return(angle)           #return angle in degrees\n",
    "\n",
    "\n",
    "#The following is for testing\n",
    "angle=mean_angular_direction(x,y)\n",
    "angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "#### We can now calculate the x_total and y_total since we have previously calculated the x_length and y_length for every data point, and then use the defined function to compute the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "x_total_VI_n = np.sum(ice_directions_VI_n['x_length'])\n",
    "y_total_VI_n = np.sum(ice_directions_VI_n['y_length'])\n",
    "northern_mean = mean_angular_direction(x_total_VI_n,y_total_VI_n)\n",
    "print(x_total_VI_n,y_total_VI_n,northern_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "make_rose_diagram(ice_directions_VI_n['Azimuth'],color='orange',title='northern Victoria ice flow',mean_direction=northern_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "<font color=goldenrod>**_Code for you to write_**</font>\n",
    "\n",
    "Calculate the x_total and y_total for the central VI data and then the mean central VI ice flow directions. Plot the observed directions and their mean on a rose diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "## Are the central Victoria and northern Victoria ice flow directions antiparallel to one another?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "print(northern_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "print(central_mean+180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "central_mean+180 == northern_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "### How well do we know the mean directions? \n",
    "\n",
    "But there is scatter in the data. How well do we know the mean directions? \n",
    "\n",
    "If we were assuming a distribution, we could calculate a confidence interval (a standard deviation for example), but we don't know what the distribution can be. We can use the data set itself as an approximation of the population and resampling from it using a statistical technique called [the bootstrap](https://www.inferentialthinking.com/chapters/13/2/Bootstrap.html) calculating the mean each time.\n",
    "\n",
    "We can again use the pandas function ```.sample``` to do the resampling. In this case, we will want `n` to be set to be the size of dataset and ```replace=True``` so that samples may be taken more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "north_mean_angles = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "<font color=goldenrod>**_Code for you to finish_**</font>\n",
    "\n",
    "Repeat for the **antipode** of central directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "central_mean_angles = []\n",
    "\n",
    "for n in range(0,10000):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "Plot a histogram of the mean resampled directions and their 95% percent confidence intervals. To plot the the confidence interval we'll add veritcal lines (with `plt.axvline()`) at the 2.5 and 97.5 percentiles (computed for example: `x=np.percentile(north_mean_angles,2.5)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.hist(north_mean_angles,alpha=0.5,density=True,color='orange',label='bootstrap resampled northern mean')\n",
    "plt.axvline(x=np.percentile(north_mean_angles,2.5),linestyle='--',color='orange',label='95% confidence interval on northern mean')\n",
    "plt.axvline(x=np.percentile(north_mean_angles,97.5),linestyle='--',color='orange')\n",
    "\n",
    "plt.hist(central_mean_angles,alpha=0.5,density=True,color='red',label='bootstrap resampled antipode of central mean')\n",
    "plt.axvline(x=np.percentile(central_mean_angles,2.5),linestyle='--',color='red',label='95% confidence interval on central mean')\n",
    "plt.axvline(x=np.percentile(central_mean_angles,97.5),linestyle='--',color='red')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim(265, 360)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "Can we say that the northern mean and the antipode of the central mean are distinct?\n",
    "\n",
    "**write your answer here and explain why**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "include"
    ]
   },
   "source": [
    "### Turn in the Notebook\n",
    "\n",
    "**Run the cell below to export this notebook as a pdf and upload to bCourses. Make sure to run all cells and save before doing so for changes to be reflected in the pdf.**\n",
    " <!-- END QUESTION -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = otter.Notebook()\n",
    "from otter.export import export_notebook\n",
    "from IPython.display import display, HTML\n",
    "export_notebook(\"W07_InClass_Ice_Sheets.ipynb\", filtering=True, pagebreaks=False)\n",
    "display(HTML(\"<p style='font-size:20px'> <br>Save this notebook, then click <a href='W07_InClass_Ice_Sheets.pdf' download>here</a> to open the pdf.<br></p>\"))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
